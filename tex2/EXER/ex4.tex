\chapter*{Multiple Markov chains and the Multiple Histogram Method}

\section{Multiple Markov chain}

We will consider of $N = 64$ identical particles in a $2$-dimensional square box of side $L$ with periodic boundary condition. We will not use $L = 6$ as suggested, since this will create an impossible configuration (there's no room to accomodate all $N$ particles); instead, we chose $L =16$, so that $\rho = 0.25$. 
The pair interaction potential is the usual square-well volume excluding potential:
\begin{equation}
	U(r) = 
	\begin{cases}
		+\infty \mbox{ for } r < R_c \\
		-\epsilon \mbox{ for } R_c < r < R_a \\
		0 \mbox{ for } r > R_a
	\end{cases}
\end{equation}
where $R_c = 1, \varepsilon = 1, R_a = 1.5$ and $k_B = 1$.

In this first task, we will implement a Metropolis Monte Carlo algorithm for this system to simulate in parallel replicas of the system
at different inverse temperatures:
$$
\beta \in \{1, 1.2, 1.4, 1.6,  1.8, 2, 2.2, 2.4\}\footnote{The temperatures used here are different from the one proposed in the homework assignment. This is because the system where $L =16$ undergoes a phase transition when $T \approx 0.6$ or $\beta \approx 1.6$}.
$$

Within each chain, the particles move through single-particle displacements. Moves that produce overlaps $r < R_c$ are automatically rejected, otherwise they are accepted with the Metropolis rule. Every $n_{swap}$ sweeps
(where a sweep corresponds to $N$ attempted single moves in each of the $K = 8$ Markov chains), attempt a swap of configurations between randomly picked neighboring replicas $k$ and $k + 1$, with acceptance probability as to fulfill detailed balance for the joint probability density functions of all $8$ systems.

\paragraph{Code implementation}
The vast majority of the code for this assignment was simply copied from the codebase of Exercise 1: The Hard Sphere model (where the interaction range was set to $R_a = 1.5$). Instead of launching just one Markov chain, we spawn a set of $K = 8$ threads that will each run an independent instance of a Markov chain with a specific temperature $\beta$. Each thread will run in parallel with the others until $n_{swap}$ steps have been performed. When this happens, all thread synchronize and the master thread will handle the Metropolis swap between two randomly selected configurations. 

Let us first verify as a sanity check that adding the parallel tempering procedure provides stable and reasonable results. In Fig.\ref{fig:HistogramsParallelTempering} we illustrate the potential energy histograms and trace plots for $3$ distinct values of $\beta$ ($1.2, 1.6, 2.2$, meaning $T \approx 0.83, 0.625, 0.45$), with and without parallel tempering. The total number of MC steps is set to $N_{MC} = 10^6$ and $n_{sweep} = 1000$, so that, on average, each configuration will stay at a fixed temperature for about $8000$ MC steps and should experience $\approx 100$ swaps during a full run.

\begin{figure}
	\centering
	\includegraphics[scale = 0.55]{./FIG/Energy_Histograms.pdf}
	\caption{\textit{efwf}}
	\label{fig:HistogramsParallelTempering}
\end{figure}

Having a closer look at Fig.\ref{fig:HistogramsParallelTempering}, one can easily see that the histograms and trace plots obtained using parallel tempering are quite identical (up to normal stochastic fluctuations) to the one generated by single independent Markov chains (obtained by setting $n_{sweep} = N_{MC}$), confirming that the implementation of the algorithm was successful. Furthermore, both algorithms converge nicely to the target distribution (in this case, the joint PDF for all Markov chains) as indicated by the initial transient in the $\beta = 2.2$ panel, hence we are effectively producing equilibrated samples at a fixed temperature. The reasons why we don't see any difference is because the temperatures here are still sufficiently high and there is no significative benefit in using parallel tempering against standard Metropolis (we will explore the low temperatures regime in the next paragraph). 

\paragraph{Energy and specific heat}
Now that we have multiple samples extracted from the equilibrium Boltzmann distribution at different $\beta_k$, we can compute various observables of interest such as the potential energy per particle $U/N$ and the specific heat per particle $C/N$\footnote{As highlighted in the first chapter, a MC simulation can only "sample" the configurational phase space of the system, since we are totally neglecting the momenta phase space dynamics. When we talk about energy, we are actually referring to the \textit{potential energy}. The specific heat is thus computed as a measure of fluctuations over the \textit{potential energy} distribution and not on the full energy distribution. However, this is not a problem as far as we're concerned: if we are looking for a divergence in the specific heat and we don't care about the correct numerical values, then considering only $U$ should be enough, because the critical singularity is due to the fact that the system suddenly changes geometry (from disordered gas to ordered fluid) and this can be seen by inspecting the potential energy.}. Results are shown in Fig. \ref{fig:EnergySpecificHeatPT}

\begin{figure}
	\centering
	\includegraphics[scale = 0.5]{./FIG/Energy_SpecificHeat_PT.pdf}
	\caption{\textit{ed}}
	\label{fig:EnergySpecificHeatPT}	
\end{figure}

The average potential energy of the system decreases monotonically as the temperature gets lower, as expected. The specific heat plot reveals a phase transition around $T \approx 0.55$. This corresponds to a liquid-gas phase transition: when the temperature is high enough (above the critical value, which is defined only in the thermodynamic limit), the particles have sufficient thermal energy to travel freely in the square box in a disordered gas phase. The residual energy we observe (for $T \to \infty$) is simply due to the finiteness of the box, forcing particles to interact temporarily (Van der Waals interactions). On the contrary, when $T < T_c$ the energy drops down and it's more thermodynamically favorable for the system to condense and form denser cluster of liquid where particles are permanently surrounded by other particles.

We can use OVITO as we did in the previous sections to visually inspect some configurations at different temperature and verify whether a phase transition is really occurring (Fig.\ref{fig:OVITOPT}). As expected, when $\beta$ is high (low $T$) the system evolves towards liquid configurations, where particles cluster together in droplets. As $\beta$ decreases, those droplets become more and more "fuzzy" (coexistence region, stable liquid droplets coexist with a stable disordered gas) until a totally gaseous phase is reached.

\begin{figure}
	\centering
	\includegraphics[scale = 0.1]{./FIG/beta2.2_Swap}
	\includegraphics[scale = 0.1]{./FIG/beta2.4_Swap}
	\includegraphics[scale = 0.1]{./FIG/beta2.0_Swap}
	\includegraphics[scale = 0.1]{./FIG/beta1.8_Swap}
	\includegraphics[scale = 0.1]{./FIG/beta1.6_Swap}
	\includegraphics[scale = 0.1]{./FIG/beta1.4_Swap}
	\includegraphics[scale = 0.1]{./FIG/beta1.2_Swap}
	\includegraphics[scale = 0.1]{./FIG/beta1.0_Swap}
	\caption{\textit{edec}}
	\label{fig:OVITOPT}
\end{figure}

\paragraph{Swap rates and Parallel tempering}
In this paragraph, we will delve deeper into the parallel tempering procedure. In previous simulations, we always used $N_{MC} = 10^6$ and $n_{swaps} = 1000$, ensuring a fair number of possible swaps between configurations. In particular, during one of the run, we measured:
\\
$$
\mbox{ Total swap acceptance ratio: } 31.9 \%
$$
\begin{itemize}
	\centering
	\item Chain 0 ($\beta=1$): 53 swaps.
	\item Chain 1 ($\beta=1.2$): 92 swaps.
	\item Chain 2 ($\beta=1.4$): 73 swaps.
	\item Chain 3 ($\beta=1.6$): 61 swaps.
	\item Chain 4 ($\beta=1.8$): 72 swaps.
	\item Chain 5 ($\beta=2$): 97 swaps.
	\item Chain 6 ($\beta=2.2$): 121 swaps.
	\item Chain 7 ($\beta=2.4$): 69 swaps.
\end{itemize}
The swap rate is satisfactory. Each chain experienced an average of $\approx 80$ swaps whose length was about $10^6 / 80 \approx 12000$ Monte Carlo steps each. At a first glance, there seems to be a significative imbalance between the number of swaps at each value of $\beta$. However, this can be easily explained by considering that, in our implementation of the parallel tempering algorithm, we only swap between neighboring temperatures, penalizing extreme values ($\beta = 1, \beta = 2.4$) that only experience about half of the expected number of swaps. But there's more: when $\beta = 1.6$, the number of exchanges is at its lowest (ignoring border values). This might seem strange at first, considering that the Metropolis acceptance probability depends on $\Delta \beta$ which is fixed here. However, one should not forget that it also depends n $\Delta E$, i.e. the energy difference between configurations. Around the critical point, it might happen that the two candidate configurations are in two different phases, one liquid the other one gaseous, hence $\Delta E$ is larger compared to chains where $\beta$ is far from the critical point (and both configurations are in the same phase). 

In Fig.\ref{fig:PathPT}, we can appreciate the swaps taking place from the perspective of a fixed Markov chain (defined according to the initial temperature). The parallel tempering algorithm allows the diffusion of each configuration over time from cold to hot conditions and back.

\begin{figure}
	\centering
	\includegraphics[scale = 0.55]{./FIG/TemperaturePaths.pdf}
	\caption{\textit{ioin}}
	\label{fig:PathPT}
\end{figure}




\paragraph{Low temperatures regime}
Up until now, there was no reason to believe parallel tempering can actually be superior with respect to the usual Metropolis algorithm when it comes to sample from Boltzmann equilibrium distributions. In Fig. \ref{fig:HistogramsParallelTempering}, both procedures (with and without parallel tempering) seem to reproduce the same curve, up to statistical errors. Let's see what happens when the chosen temperatures $\beta_k$ are lower than before:
$$
\beta \in \{4,5,6,7,8,9,10,11\}
$$
Results concerning energy histograms and trace plots are shown in Fig.\ref{fig:HistogramsLowt}. When $\beta = 4 (T = 0.25)$, there still is no sensible difference when using parallel tempering. However, a completely different scenario emerges when $\beta = 8$ or $\beta = 11$ (corresponding to $T = 0.125$, $T = 0.09$). Both simulations seem to have found a stationary state, i.e. a minimum of the free energy, even though the average (potential) energy per particle is definitely not the same. What's the reason behind this strange behavior? Why is the average energy per particle lower when parallel tempering is used?

The reason is that, when $T$ is extremely low, the free energy landscape becomes particularly complex. Imagine a configuration where particles are distributed in two distinct but similar clusters (or droplets). This is not yet the equilibrium configuration, but rather a \textit{metastable state}. To further decrease the energy (which is essential in the low $T$ regime, where the entropic term is negligible), the system should make the two droplets merge. For this to happen, particles on the boundary of one cluster should evaporate and then attach to the other droplet. The difference in energy associated to the evaporation of an external particle is about $\Delta E = -3$ ($3$ particles on one side, none on the other). When $\beta = 8$, for example, the associated Metropolis acceptance rate for this move is $\exp(-3 \cdot 8) = \exp(-24) \approx 10^{-11}$. Hence, if the system collapses into one of these multi-cluster metastable states, the usual Metropolis algorithm is unable to nudge away from these configurations. This is also called \textit{quasi-ergodicity}, i.e. the fact that a small portion of the phase space is explored but never abandoned to reach other relevant portions because the intermediate states are very unlikely. 

\begin{figure}
	\centering
	\includegraphics[scale = 0.55]{./FIG/Energy_Histograms_LowT}
	\caption{\textit{ded}}
	\label{fig:HistogramsLowt}
\end{figure}

With parallel tempering, this problem is solved by frequently switching configurations (provided this swapping rule obeys detailed balance). The system should now be able to relax to low energy states, as it should be in the low temperature regime. In Fig.\ref{fig:comparaison}, this difference is illustrated with two snapshots coming from the same $\beta$ with and without parallel tempering.

\begin{figure}
	\centering
	\includegraphics[scale = 0.255]{./FIG/PT}
	\includegraphics[scale = 0.2]{./FIG/NoPT}
	\caption{\textit{ec}}
	\label{fig:comparaison}
\end{figure}

\paragraph{A new phase transition}
Let's plot the average (potential) energy per particle and the specific heat per particle at low temperatures. Results are shown in Fig.\ref{fig:energy_lowT}
\begin{figure}
	\centering
	\includegraphics[scale = 0.5]{./FIG/Energy_SpecificHeat_LowT.pdf}
	\caption{\textit{ced}}
	\label{fig:energy_lowT}
\end{figure}
The supremacy of parallel tempering is now much more evident. The green line (no parallel tempering) is completely wrong when $T < 0.22$; the correct behavior is recovered only by the blue line. An interesting feature that can be observed by inspecting Fig.\ref{fig:comparaison} is that the specific heat displays a new peak around $T \approx 0.2$.

This should be caused by a brand new phase transition, from a cluster liquid phase to a \textit{cluster crystalline structure}. Particles are still trapped in dense clusters, but now they arrange in a rigid crystalline structure which is denser and that further decreases the potential energy of the system (Fig.\ref{fig:secondPhaseTransition})

\begin{figure}
	\centering
	\includegraphics[scale = 0.14]{./FIG/beta3.0}
	\includegraphics[scale = 0.14]{./FIG/beta4.0}
	\includegraphics[scale = 0.14]{./FIG/beta5.0}
	\includegraphics[scale = 0.14]{./FIG/beta6.0}
	\vspace{5pt}
	\includegraphics[scale = 0.14]{./FIG/beta7.0}
	\includegraphics[scale = 0.14]{./FIG/beta8.0}
	\includegraphics[scale = 0.14]{./FIG/beta9.0}
	\includegraphics[scale = 0.14]{./FIG/beta10.0}
	\caption{\textit{edec}}
	\label{fig:secondPhaseTransition}
\end{figure}

We can clearly see that particles now form densely-packed clusters where every atom has $8$ neighbors (i.e. a \textit{crystal}). When $T \to 0$, this would mean that we should observe a potential energy of $U/N = -4$, which is not the case as depicted in Fig.\ref{fig:energy_lowT}. This is simply due to a finite size effect: particles located at the borders cannot create bonds with $8$ neighbors, hence increasing by a small amount the total energy of the system\footnote{When $N\to\infty$, the number of border particles become negligible when compared to the number of bulk particles, so we should be able to asymptotically reach $U(T = 0) = -4$ performing a thermodynamic limit.}


\section{Multiple Histogram Method (MHM)}
